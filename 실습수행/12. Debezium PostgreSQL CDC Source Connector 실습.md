# Debezium PostgreSQL CDC Source Connector ì‹¤ìŠµ

### PostgreSQL ì„¤ì¹˜í•˜ê¸°(ê¸° ì ìš©ë¨)

- ì‹¤ìŠµ í™˜ê²½ ì‹œìŠ¤í…œ update && upgrade

```sql
sudo apt update
sudo apt -y upgrade
```

- postgresql ì„¤ì¹˜

```sql
sudo apt install postgresql postgresql-client
```

### PostgreSQL DB í™˜ê²½ êµ¬ì¶•(ê¸° ì ìš©ë¨)

- postgres os ì‚¬ìš©ìë¡œ ë¡œê·¸ì¸í•œ ë’¤ /etc/postgresql/12/main ë””ë ‰í† ë¦¬ë¡œ ì´ë™.

```sql
sudo su - postgres
cd /etc/postgresql/12/main
```

- postgresql.conf ì˜ listen_addresses ì„¤ì •ì„ â€˜*â€™ ìœ¼ë¡œ, Debeziumì—ì„œ replication ì ìš©í•˜ê¸° ìœ„í•´ wal_level = logical ìœ¼ë¡œ ë³€ê²½.

```sql
listen_addresses = '*'

wal_level = logical
```

- pg_hba.confì˜ ì•„ë˜ IPV4ì˜ addressë¥¼ 0.0.0.0/0 ìœ¼ë¡œ ë³€ê²½

```sql
# "local" is for Unix domain socket connections only
local   all             all                                     md5

# IPv4 local connections:
host    all             all             0.0.0.0/0            md5
```

- postgresql ì¬ ê¸°ë™.

```sql
sudo systemctl restart postgresql
```

### ì‹¤ìŠµìš© ì‚¬ìš©ì ìƒì„±(ê¸° ì ìš©ë¨)

- postgres OS ì‚¬ìš©ìë¡œ ì ‘ì†í•˜ì—¬ psql ìˆ˜í–‰

```sql
sudo su - postgres
psql
```

- psql ì ‘ì†

```sql
sudo su - postgres
psql
```

- ìƒˆë¡œìš´ user connect_dev ìƒì„±.

```sql
create user connect_dev password 'connect_dev';
alter user connect_dev createdb;
grant all privileges on database postgres to connect_dev;
```

- ìƒˆë¡œìš´ userì¸ connect_devë¡œ postgres DB ì ‘ì†

```sql
psql -h localhost -U connect_dev -d postgres
```

- psqll ì ‘ì† í›„ ì ‘ì† DB í™•ì¸ ë° ì‹ ê·œ ìŠ¤í‚¤ë§ˆ op_sink ìƒì„±.

```sql
\conninfo
\l
create schema ops_sink;
\dn
```

### Source ë° Sink DB ìƒì„± ë° Replication userì¸ connect_devì— replication ê¶Œí•œ ë¶€ì—¬

- psqlì—ì„œ postgres ìœ ì €ì˜ password ë³€ê²½

```sql
sudo su - postgres
psql

\du
alter user postgres with password 'postgres';
```

- í˜„ì¬ DB ë¦¬ìŠ¤íŠ¸ ë° ì ‘ì† ì •ë³´ ì¡°íšŒ

```sql
\l
\conninfo
```

- oc database ìƒì„±

```sql
create database oc;

create database oc_sink;
```

- ë³µì œë¥¼ ìœ„í•´ connect_dev ì‚¬ìš©ìì— superuser, login, replication role í• ë‹¹í•˜ê³  oc ë° oc_sink ë°ì´í„°ë² ì´ìŠ¤ ê¶Œí•œ ë¶€ì—¬

```sql

alter user connect_dev with superuser login replication;
\du

grant all privileges on database oc to connect_dev;
grant all privileges on database oc_sink to connect_dev;
```

- connect_dev ì‚¬ìš©ìë¡œ oc DBì ‘ì† í›„ DB Encoding ì •ë³´ í™•ì¸.

```sql
psql -h localhost -U connect_dev -d oc

\conninfo
SHOW SERVER_ENCODING;
```

- ì•„ë˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìˆ˜í–‰í•˜ì—¬ oc ë°ì´í„°ë² ì´ìŠ¤ì˜ public schema ì— customers, products, orders, order_items í…Œì´ë¸” ìƒì„±

```sql
\connect oc;

drop table public.customers; 
drop table public.products; 
drop table public.orders; 
drop table public.order_items; 

CREATE TABLE public.customers (
	customer_id int NOT NULL PRIMARY KEY,
	email_address varchar(255) NOT NULL,
	full_name varchar(255) NOT NULL
);

CREATE TABLE public.products (
	product_id int NOT NULL PRIMARY KEY,
	product_name varchar(100) NULL,
	product_category varchar(200) NULL,
	unit_price numeric NULL
);

CREATE TABLE public.orders (
	order_id int NOT NULL PRIMARY KEY,
	order_datetime timestamp NOT NULL,
	customer_id int NOT NULL,
	order_status varchar(10) NOT NULL,
	store_id int NOT NULL
) ;

CREATE TABLE public.order_items (
	order_id int NOT NULL,
	line_item_id int NOT NULL,
	product_id int NOT NULL,
	unit_price numeric(10, 2) NOT NULL,
	quantity int NOT NULL,
	primary key (order_id, line_item_id)
);

\dt
\d customers
\d products
\d orders
\d order_items


select count(*) from public.customers union all
select count(*) from public.products union all
select count(*) from public.orders union all
select count(*) from public.order_items;



```

- ì•„ë˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìˆ˜í–‰í•˜ì—¬ oc_sink ë°ì´í„°ë² ì´ìŠ¤ì˜ public schema ì— customers_sink, products_sink, orders_sink, order_items_sink í…Œì´ë¸” ìƒì„±

```sql
\connect oc_sink;
\conninfo;

drop table public.customers_sink; 
drop table public.products_sink; 
drop table public.orders_sink; 
drop table public.order_items_sink; 

CREATE TABLE public.customers_sink (
	customer_id int NOT NULL PRIMARY KEY,
	email_address varchar(255) NOT NULL,
	full_name varchar(255) NOT NULL
);

CREATE TABLE public.products_sink (
	product_id int NOT NULL PRIMARY KEY,
	product_name varchar(100) NULL,
	product_category varchar(200) NULL,
	unit_price numeric NULL
);

CREATE TABLE public.orders_sink (
	order_id int NOT NULL PRIMARY KEY,
	order_datetime timestamp NOT NULL,
	customer_id int NOT NULL,
	order_status varchar(10) NOT NULL,
	store_id int NOT NULL
) ;

CREATE TABLE public.order_items_sink (
	order_id int NOT NULL,
	line_item_id int NOT NULL,
	product_id int NOT NULL,
	unit_price numeric(10, 2) NOT NULL,
	quantity int NOT NULL,
	primary key (order_id, line_item_id)
);

\dt
\d customers_sink
\d products_sink
\d orders_sink
\d order_items_sink


select count(*) from public.customers_sink union all
select count(*) from public.products_sink union all
select count(*) from public.orders_sink union all
select count(*) from public.order_items_sink;

```

```declarative

kafka-topics --bootstrap-server localhost:9092 --create --topic pgavro-public-customers --partitions 3
kafka-topics --bootstrap-server localhost:9092 --create --topic pgavro-public-orders --partitions 3
kafka-topics --bootstrap-server localhost:9092 --create --topic pgavro-public-products --partitions 3
kafka-topics --bootstrap-server localhost:9092 --create --topic pgavro-public-order_items --partitions 3
kafka-topics --bootstrap-server localhost:9092 --create --topic pgavro-public-boards --partitions 3

```


### ExtractNewRecordState SMT ì ìš©í•˜ì—¬ Source Connector ìƒì„±

- postgres_cdc_oc_source_01.json íŒŒì¼ì— ì•„ë˜ ì„¤ì • ì €ì¥.

```sql
{
    "name": "postgres_cdc_oc_source_01",
    "config": {
        "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
        "database.hostname": "localhost",
        "database.port": "5432",
        "database.user": "connect_dev",
        "database.password": "1111",
        "database.dbname": "oc",
        "database.server.name": "pg01",

        "plugin.name": "pgoutput",
        "slot.name": "debezium_01",

        "schema.include_list": "public",
        "table.include.list": "public.customers, public.products, public.orders, public.order_items",

        "key.converter": "org.apache.kafka.connect.json.JsonConverter",
        "value.converter": "org.apache.kafka.connect.json.JsonConverter", 
        
        "transforms": "unwrap",
        "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
        "transforms.unwrap.drop.tombstones": "false"

    }
}
```

- í•´ë‹¹ íŒŒì¼ì„ Connectì— ë“±ë¡í•˜ì—¬ ì‹ ê·œ Connector ìƒì„±

```sql
register_connector postgres_cdc_oc_source_01.json
show_connectors
```

- customers, orders, products, order_itemsì— ë°ì´í„° ì…ë ¥

```sql
sudo su - postgres
psql -h localhost -U connect_dev -d oc;

\conninfo

insert into customers values (1, 'testaddress_01@testdomain', 'testuser_01');
insert into customers values (2, 'testaddress_02@testdomain', 'testuser_02');
insert into orders values(1, now(), 1, 'delivered', 1);
insert into products values(1, 'testproduct', 'testcategory', 100);
insert into order_items values(1, 1, 1, 100, 1);

```




```declarative

CREATE OR REPLACE PROCEDURE insert_test_data(
    p_start_id INT,
    p_end_id INT,
    p_batch_size INT,
    p_delay_seconds decimal(10,3)
)
    LANGUAGE plpgsql
    AS $$
    DECLARE
    i INT;
    batch_counter INT := 0;
BEGIN
    -- customers
    FOR i IN p_start_id..p_end_id LOOP
        INSERT INTO public.customers (customer_id, email_address, full_name)
            VALUES (
            i,
            'user' || i || '@example.com',
            'Test User ' || i
        );
        
        batch_counter := batch_counter + 1;
        IF batch_counter % p_batch_size = 0 THEN
            PERFORM pg_sleep(p_delay_seconds);
        END IF;
        -- products
        INSERT INTO public.products (product_id, product_name, product_category, unit_price)
        VALUES (
            i,
            'Product ' || i,
            CASE WHEN i % 2 = 0 THEN 'Electronics' ELSE 'Books' END,
            ROUND((random() * 100 + 1)::numeric, 2)
        );
        IF batch_counter % p_batch_size = 0 THEN
            PERFORM pg_sleep(p_delay_seconds);
        END IF;
        
        -- orders
        INSERT INTO public.orders (order_id, order_datetime, customer_id, order_status, store_id)
        VALUES (
            i,
            NOW() - (p_end_id - i) * INTERVAL '1 day',
            i,
            CASE WHEN i % 3 = 0 THEN 'DONE' ELSE 'PENDING' END,
            (i % 5) + 1
        );
        IF batch_counter % p_batch_size = 0 THEN
            PERFORM pg_sleep(p_delay_seconds);
        END IF;
    
    
        -- order_items
        INSERT INTO public.order_items (order_id, line_item_id, product_id, unit_price, quantity)
        VALUES (
            i,
            1,
            i,
            ROUND((random() * 100 + 1)::numeric, 2),
            (i % 5) + 1
        );
        IF batch_counter % p_batch_size = 0 THEN
            COMMIT;
            PERFORM pg_sleep(p_delay_seconds);
        END IF;
            
    END LOOP;

END;
$$;


```

ğŸ“Œ ì‹¤í–‰ ì˜ˆì‹œ
``` sql
-- ID 1~10ê¹Œì§€ ë°ì´í„°ë¥¼ ìƒì„±í•˜ë©´ì„œ ê° INSERTë§ˆë‹¤ 1ì´ˆ ëŒ€ê¸°
CALL insert_test_data(1, 1000, 100, 0.0);


1ë¶€í„° 100ê¹Œì§€ ê° í…Œì´ë¸”ì— ë°ì´í„° ìƒì„±
10ê±´ë§ˆë‹¤ 1ì´ˆì”© ë”œë ˆì´
```



- í† í”½ ìƒì„± ë° í† í”½ ë©”ì‹œì§€ í™•ì¸

```sql
show_topic_messages json pg.public.customers
```

### JDBC Sink Connectorë¡œ ë°ì´í„° ì…ë ¥

- oc_sink DBì— í† í”½ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ëŠ” Connectorë¥¼ ì•„ë˜ì™€ ê°™ì´ ìƒì„±
- postgres_jdbc_oc_sink_customers_01.json íŒŒì¼ì— ì•„ë˜ ì„¤ì • ì €ì¥

```sql
{
    "name": "postgres_jdbc_oc_sink_customers_01",
    "config": {
        "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
        "tasks.max": "1",
        "topics": "pgavro-public-customers",
        "connection.url": "jdbc:postgresql://localhost:5432/oc_sink",
        "connection.user": "connect_dev",
        "connection.password": "1111",
        "table.name.format": "public.customers_sink",

        "insert.mode": "upsert",
        "pk.fields": "customer_id",
        "pk.mode": "record_key",
        "delete.enabled": "true",

        "auto.evolve": "true",
        
        "transforms": "flattenValue,convertTS",
        "transforms.flattenValue.type": "org.apache.kafka.connect.transforms.Flatten$Value",
        "transforms.convertTS.type": "org.apache.kafka.connect.transforms.TimestampConverter$Value",
        "transforms.convertTS.field": "order_datetime",
        "transforms.convertTS.format": "yyyy-MM-dd'T'HH:mm:ss'Z'",
        "transforms.convertTS.target.type": "Timestamp",

        "key.converter": "io.confluent.connect.avro.AvroConverter",
        "value.converter": "io.confluent.connect.avro.AvroConverter",
        "key.converter.schema.registry.url": "http://localhost:8081",
        "value.converter.schema.registry.url": "http://localhost:8081"
    }
}
```


- postgres_jdbc_oc_sink_products_01.json íŒŒì¼ì— ì•„ë˜ ì„¤ì • ì €ì¥

```sql
{
    "name": "postgres_jdbc_oc_sink_products_01",
    "config": {
        "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
        "tasks.max": "1",
        "topics": "pgavro-public-products",
        "connection.url": "jdbc:postgresql://localhost:5432/oc_sink",
        "connection.user": "connect_dev",
        "connection.password": "1111",
        "table.name.format": "public.products_sink",

        "insert.mode": "upsert",
        "pk.fields": "product_id",
        "pk.mode": "record_key",
        "delete.enabled": "true",

        "auto.evolve": "true",
        
        "transforms": "flattenValue,convertTS",
        "transforms.flattenValue.type": "org.apache.kafka.connect.transforms.Flatten$Value",
        "transforms.convertTS.type": "org.apache.kafka.connect.transforms.TimestampConverter$Value",
        "transforms.convertTS.field": "order_datetime",
        "transforms.convertTS.format": "yyyy-MM-dd'T'HH:mm:ss'Z'",
        "transforms.convertTS.target.type": "Timestamp",

        "key.converter": "io.confluent.connect.avro.AvroConverter",
        "value.converter": "io.confluent.connect.avro.AvroConverter",
        "key.converter.schema.registry.url": "http://localhost:8081",
        "value.converter.schema.registry.url": "http://localhost:8081"
    }
}
```


- postgres_jdbc_oc_sink_orders_01.json íŒŒì¼ì— ì•„ë˜ ì„¤ì • ì €ì¥

```sql
{
    "name": "postgres_jdbc_oc_sink_orders_01",
    "config": {
        "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
        "tasks.max": "1",
        "topics": "pgavro-public-orders",
        "connection.url": "jdbc:postgresql://localhost:5432/oc_sink",
        "connection.user": "connect_dev",
        "connection.password": "1111",
        "table.name.format": "public.orders_sink",

        "insert.mode": "upsert",
        "pk.fields": "order_id",
        "pk.mode": "record_key",
        "delete.enabled": "true",

        "auto.evolve": "true",
        
        "transforms": "flattenValue,convertTS",
        "transforms.flattenValue.type": "org.apache.kafka.connect.transforms.Flatten$Value",
        "transforms.convertTS.type": "org.apache.kafka.connect.transforms.TimestampConverter$Value",
        "transforms.convertTS.field": "order_datetime",
        "transforms.convertTS.format": "yyyy-MM-dd'T'HH:mm:ss'Z'",
        "transforms.convertTS.target.type": "Timestamp",

        "key.converter": "io.confluent.connect.avro.AvroConverter",
        "value.converter": "io.confluent.connect.avro.AvroConverter",
        "key.converter.schema.registry.url": "http://localhost:8081",
        "value.converter.schema.registry.url": "http://localhost:8081"
    }
}
```


- postgres_jdbc_oc_sink_order_items_01.json íŒŒì¼ì— ì•„ë˜ ì„¤ì • ì €ì¥

```sql
{
    "name": "postgres_jdbc_oc_sink_order_items_01",
    "config": {
        "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
        "tasks.max": "1",
        "topics": "pgavro-public-order_items",
        "connection.url": "jdbc:postgresql://localhost:5432/oc_sink",
        "connection.user": "connect_dev",
        "connection.password": "1111",
        "table.name.format": "public.order_items_sink",

        "insert.mode": "upsert",
        "pk.fields": "order_id, line_item_id",
        "pk.mode": "record_key",
        "delete.enabled": "true",

        "auto.evolve": "true",
        
        "transforms": "flattenValue,convertTS",
        "transforms.flattenValue.type": "org.apache.kafka.connect.transforms.Flatten$Value",
        "transforms.convertTS.type": "org.apache.kafka.connect.transforms.TimestampConverter$Value",
        "transforms.convertTS.field": "order_datetime",
        "transforms.convertTS.format": "yyyy-MM-dd'T'HH:mm:ss'Z'",
        "transforms.convertTS.target.type": "Timestamp",

        "key.converter": "io.confluent.connect.avro.AvroConverter",
        "value.converter": "io.confluent.connect.avro.AvroConverter",
        "key.converter.schema.registry.url": "http://localhost:8081",
        "value.converter.schema.registry.url": "http://localhost:8081"
    }
}
```







- jdbc sink connector ë“±ë¡

```sql
register_connector postgres_jdbc_oc_sink_customers_01.json
show_connectors
```

- oc_sink DBì— ì ‘ì†í•˜ì—¬ customers_sink í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì…ë ¥ë˜ì—ˆëŠ”ì§€ í™•ì¸

```sql

\connect oc_sink
select * from customers_sink;
```










### Source Connectorì—ì„œ Publication ìƒì„± ë° ì ìš©

- ëª¨ë“  í…Œì´ë¸”ì— ëŒ€í•´ì„œ publicationì„ ì ìš©í•˜ëŠ” dbz_publication ìƒì„±ì´ ë˜ì–´ ìˆìŒì„ í™•ì¸. slot ì •ë³´ë„ í•¨ê»˜ í™•ì¸. pg_replication_slotsëŠ” ëª¨ë“  dbì— ëŒ€í•œ replication slotì •ë³´ë¥¼ ê°€ì§€ê³  ìˆìŒ.

```sql
\connect oc

select * from pg_publication;

select * from pg_replication_slots;
```

- PKê°€ ì—†ëŠ” ì„ì˜ì˜ í…Œì´ë¸”ì„ ìƒì„± í›„ ë°ì´í„° ì…ë ¥. ë ˆì½”ë“œ ì‚­ì œ ìˆ˜í–‰ ì‹œ ì˜¤ë¥˜ ë°œìƒ.  ë ˆì½”ë“œ ìì²´ë¥¼ identityë¥¼ ì„¤ì •í•˜ë©´ ë¬¸ì œ ì—†ì´ ì‚­ì œë¨.

```sql
create table no_pk_tab
( col1 integer);

insert into no_pk_tab values (1);

-- ì•„ë˜ëŠ” ì˜¤ë¥˜ ë°œìƒ. 
delete from no_pk_tab;

ALTER TABLE no_pk_tab REPLICA IDENTITY FULL;

delete from no_pk_tab;
```

- PKê°€ ìˆëŠ”  í…Œì´ë¸”ì˜ ë ˆì½”ë“œ ì‚­ì œëŠ” ë¬¸ì œ ì—†ìŒ.

```sql
create table pk_tab
( col1 integer primary key);

insert into pk_tab values (1);

delete from pk_tab; 
```

- íŠ¹ì • í…Œì´ë¸”ë§Œì„ publication í•˜ëŠ” ì‹ ê·œ publication_ìƒì„±.

```sql
create publication pub_filtered for table public.customers, public.products, public.orders, public.order_items;
--create publication pub_all for all tables;
--create publication pub_schema for tables in public;

select * from pg_publication;

select * from pg_publication_tables;
```

- ê¸°ì¡´ connectorë¥¼ ì‚­ì œí•œ í›„ publicationì´ ì‚­ì œ ë˜ëŠ” ì§€ í™•ì¸.

```sql
delete_connector postgres_cdc_oc_source_01;
```

- publication ì‚­ì œ

```sql
drop publication dbz_publication;

select * from pg_publication;

-- ì•„ë˜ëŠ” relication_slot ì‚­ì œ
--select pg_drop_replication_slot('debezium_01');
```

- publication.nameì„ pub_filtered, publication.autocreate.modeë¥¼ filteredë¡œ ì„¤ì •. 
- postgres_cdc_oc_source_02.json íŒŒì¼ì— ì•„ë˜ ì„¤ì • ì €ì¥.

```sql
{
    "name": "postgres_cdc_oc_source_02",
    "config": {
        "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
        "database.hostname": "localhost",
        "database.port": "5432",
        "database.user": "connect_dev",
        "con"database.password": "1111",
        "database.dbname": "oc",
        "database.server.name": "pg02",

        "plugin.name": "pgoutput",
        "slot.name": "debezium_01",
        "publication.name": "pub_filtered",
        "publication.autocreate.mode": "filtered", 

        "schema.include_list": "public",
        "table.include.list": "public.customers, public.products, public.orders, public.order_items",

        "key.converter": "org.apache.kafka.connect.json.JsonConverter",
        "value.converter": "org.apache.kafka.connect.json.JsonConverter", 
        
        "transforms": "unwrap",
        "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
        "transforms.unwrap.drop.tombstones": "false"

    }
}
```

- publicationê³¼ replication slot ì‚­ì œ

```sql
drop publication pub_filtered;
drop publication dbz_publication;

SELECT pg_drop_replication_slot('debezium_01');
SELECT pg_drop_replication_slot('debezium_02');

```

### Source í…Œì´ë¸”ì˜ ì»¬ëŸ¼ ì¶”ê°€ì— ë”°ë¥¸ JDBC Sink Connectorì˜ Target í…Œì´ë¸” ìë™ ë°˜ì˜

- ì•„ë˜ì™€ ê°™ì´ìƒˆë¡œìš´ í…Œì´ë¸”ì„ ocì™€ oc_sink DBì— ìƒì„±.

```sql
psql -h localhost -U connect_dev -d oc

\conninfo

drop table if exists customers_redef;

-- ì•„ë˜ Create Table ìŠ¤í¬ë¦½íŠ¸ìˆ˜í–‰.
CREATE TABLE customers_redef (
      customer_id   int NOT      NULL PRIMARY KEY
    , email_address varchar(255) NOT NULL
    , full_name     varchar(255) NOT NULL
);

insert into customers_redef (customer_id, email_address, full_name) values (1, 'test', 'test');

\connect oc_sink;

drop table if exists customers_redef_sink;

-- ì•„ë˜ Create Table ìŠ¤í¬ë¦½íŠ¸ìˆ˜í–‰.
CREATE TABLE customers_redef_sink (
      customer_id   int NOT      NULL PRIMARY KEY
    , email_address varchar(255) NOT NULL
    , full_name     varchar(255) NOT NULL
);

```

- postgres_cdc_oc_source_redef.json íŒŒì¼ì— ì•„ë˜ ì„¤ì •ìœ¼ë¡œ Source Connect ìƒì„±

```sql
{
    "name": "postgres_cdc_oc_source_redef",
    "config": {
        "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
        "database.hostname": "localhost",
        "database.port": "5432",
        "database.user": "connect_dev",
        "con"database.password": "1111",
        "database.dbname": "oc",
        "database.server.name": "pgrd",

        "plugin.name": "pgoutput",
        "slot.name": "debezium_slot",

        "publication.name": "pub_schema",
        "publication.autocreate.mode": "filtered", 

        "schema.include_list": "public",
        
        "time.precision.mode": "connect",
        "database.connectionTimezone": "Asia/Seoul",

        "key.converter": "org.apache.kafka.connect.json.JsonConverter",
        "value.converter": "org.apache.kafka.connect.json.JsonConverter", 
        
        "transforms": "unwrap",
        "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
        "transforms.unwrap.drop.tombstones": "false"
    }
}
```

- auto.evolve=true ì„¤ì •ìœ¼ë¡œ 
- postgres_jdbc_oc_sink_customers_redef.json ìƒì„±.

```json
{
    "name": "postgres_jdbc_oc_sink_customers_redef",
    "config": {
        "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
        "tasks.max": "1",
        "topics": "pgrd.public.customers_redef",
        "connection.url": "jdbc:postgresql://localhost:5432/oc_sink",
        "connection.user": "connect_dev",
        "connection.password": "1111",
        "table.name.format": "public.customers_redef_sink",

        "insert.mode": "upsert",
        "pk.fields": "customer_id",
        "pk.mode": "record_key",
        "delete.enabled": "true",

        "auto.evolve": "true",

        "key.converter": "org.apache.kafka.connect.json.JsonConverter",
        "value.converter": "org.apache.kafka.connect.json.JsonConverter"
    }
}
```

- connector ìƒì„± ë“±ë¡,  topic ë©”ì‹œì§€ ë° Target í…Œì´ë¸” í™•ì¸.

```bash
register_connector postgres_cdc_oc_source_redef.json
register_connector postgres_jdbc_oc_sink_customers_redef.json

# í† í”½ ë©”ì‹œì§€ í™•ì¸
show_topic_messages json pgrd.public.customers_redef
```

- publicationê³¼ replication slot í™•ì¸.

```bash
\connect oc

select * from pg_publication;

select * from pg_replication_slots;
```

### Source í…Œì´ë¸”ì— ìˆ«ìí˜• ì»¬ëŸ¼ ì¶”ê°€

- oc DBì˜ customers_redef í…Œì´ë¸”ì— ì •ìˆ˜í˜• ì»¬ëŸ¼ ì¶”ê°€(default Null) ë° ë°ì´í„° ì…ë ¥

```sql
\connect oc;

alter table customers_redef add column age int;

\d customers_redef;

insert into customers_redef (customer_id, email_address, full_name, age) 
values (2, 'test', 'test', 40);
```

- í† í”½ ë©”ì‹œì§€ ë° Target í…Œì´ë¸” ë³€ê²½ í™•ì¸

```bash
show_topic_messages json pgrd.public.customers_redef
```

- oc DBì˜ customers_redef í…Œì´ë¸”ì— Not Null ì •ìˆ˜í˜• ì»¬ëŸ¼ ì¶”ê°€ ë° ë°ì´í„° ì…ë ¥ í›„ í† í”½ ë©”ì‹œì§€ì™€ Target í…Œì´ë¸” ë³€ê²½ í™•ì¸

```sql
\connect oc;

alter table customers_redef add column salary int not null default 0;

\d customers_redef;

insert into customers_redef (customer_id, email_address, full_name, age, salary) 
values (3, 'test', 'test', 30, 10000);
```

### Source í…Œì´ë¸”ì— varchar ì»¬ëŸ¼ ì¶”ê°€

- customers_redef í…Œì´ë¸”ì— varchar ì»¬ëŸ¼ ì¶”ê°€(Null) ë° ë°ì´í„° ì…ë ¥ í›„ í† í”½ ë©”ì‹œì§€ì™€ Target í…Œì´ë¸” ë³€ê²½ í™•ì¸

```sql
\connect oc;

alter table customers_redef add column address_01 varchar(100);

\d customers_redef;

insert into customers_redef (customer_id, email_address, full_name, age, salary, address_01) 
values (4, 'test', 'test', 30, 10000, 'test address 04');
```

- Target í…Œì´ë¸” ê°’ ë° ë°ì´í„° íƒ€ì… í™•ì¸.

```sql
\connect oc_sink;

select * from customers_redef_sink;

\d customers_redef_sink
```

- Sink Connector ìƒíƒœ ì •ì§€(ë˜ëŠ” ì‚­ì œ)

```sql
http GET http://localhost:8083/connectors/postgres_jdbc_oc_sink_customers_redef/status

delete_connector postgres_jdbc_oc_sink_customers_redef
```

- Target í…Œì´ë¸” customers_redef_sinkì˜ address_01 ì»¬ëŸ¼ì„ varchar(100)ìœ¼ë¡œ ë³€ê²½

```sql
\connect oc_sink;

alter table customers_redef_sink alter column address_01 type varchar(100);

\d customers_redef_sink;
```

- postgres_jdbc_oc_sink_customers_redef Sink Connector ì¬ ê¸°ë™ ìˆ˜í–‰.

```sql
http GET http://localhost:8083/connectors/postgres_jdbc_oc_sink_customers_redef/status

register_connector postgres_jdbc_oc_sink_customers_redef.json
```

- oc dbì—ì„œ customers_redef í…Œì´ë¸”ì— ìƒˆë¡œìš´ ë°ì´í„° ì…ë ¥ í›„ oc_sinkì—ì„œ ë°ì´í„° í™•ì¸

```sql
\connect oc;

insert into customers_redef (customer_id, email_address, full_name, age, salary, address_01) 
values (5, 'test', 'test', 30, 10000, 'test address 05');

\connect oc_sink;

select * from customers_redef;

\d customers_redef_sink;
```

### Timezoneì— ë”°ë¥¸ timestampì™€ timestamptz ì¶œë ¥ ê°’ ì°¨ì´

- timestamptz í™•ì¸

```sql
show timezone;

select now();

create table timestamp_test
(
timestamp_col timestamp,
timestamptz_col timestamptz
);

insert into timestamp_test 
values (
'2023-04-27 14:00:00',
'2023-04-27 14:00:00'
);

select * from timestamp_test;

set timezone='UTC';

select * from timestamp_test;

```

### Source í…Œì´ë¸”ì— date, timestamp, timestamptz ì»¬ëŸ¼ ì¶”ê°€

- oc dbì˜ temporal_tab í…Œì´ë¸”ì— date/timestamp/timestamptz ì»¬ëŸ¼ ìƒì„± ë° ë°ì´í„° ì…ë ¥ . ë°ì´í„° ì…ë ¥ ì „ì— pub_schema publicationì— ì‹ ê·œ í…Œì´ë¸”ì¸ temporal_tab í…Œì´ë¸” ë“±ë¡

```sql
\connect oc

create table temporal_tab
( id int primary key,
  date_col date,
  timestamp_col timestamp,
  timestamptz_col timestamptz
);

select * from pg_publication;

select * from pg_publication_tables;

alter publication pub_schema add table temporal_tab;

insert into temporal_tab values (1, '2023-04-26', '2023-04-26 19:00:00', '2023-04-26 19:00:00');
```

- connector ì¬ê¸°ë™

```sql
show_connectors

delete_connector postgres_cdc_oc_source_redef

register_connector postgres_cdc_oc_source_redef
```

- topic ë©”ì‹œì§€ í™•ì¸

```sql
show_topic_messages json pgrd.public.temporal_tab;
```

- oc_sink dbì— temporal_tab_sink í…Œì´ë¸” ìƒì„±.

```sql
\connect oc_sink;

create table temporal_tab_sink
( id int primary key,
  date_col date,
  timestamp_col timestamp,
  timestamptz_col timestamptz
);
```

- sink connector ìƒì„±. postgres_jdbc_oc_sink_temporal_tab.json íŒŒì¼ë¡œ ì„¤ì •.

```sql
{
    "name": "postgres_jdbc_oc_sink_temporal_tab",
    "config": {
        "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
        "tasks.max": "1",
        "topics": "pgrd.public.temporal_tab",
        "connection.url": "jdbc:postgresql://localhost:5432/oc_sink",
        "connection.user": "connect_dev",
        "connection.password": "1111",
        "table.name.format": "public.temporal_tab_sink",

        "insert.mode": "upsert",
        "pk.fields": "id",
        "pk.mode": "record_key",
        "delete.enabled": "true",

        "auto.evolve": "true",

        "key.converter": "org.apache.kafka.connect.json.JsonConverter",
        "value.converter": "org.apache.kafka.connect.json.JsonConverter", 

        "transforms": "convertTS",
        "transforms.convertTS.type": "org.apache.kafka.connect.transforms.TimestampConverter$Value",
        "transforms.convertTS.field": "timestamptz_col",
        "transforms.convertTS.format": "yyyy-MM-dd'T'HH:mm:ss'Z'",
        "transforms.convertTS.target.type": "Timestamp"
    }
}
```

- connector ë“±ë¡ í›„ sink í…Œì´ë¸” í™•ì¸


